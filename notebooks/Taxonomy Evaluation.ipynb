{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "103d0a0f-1c4d-4645-81d6-2061cc9fea5d",
   "metadata": {},
   "source": [
    "# Taxonomy Evaluation\n",
    "\n",
    "This notebook evaluates all of the trained taxonomy models, producing the plots for the manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1190205e-64d8-4fb8-aa52-e7e41304387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnadb import fasta, sample, taxonomy\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a5cab86-78fd-4f3f-bfeb-a88cf0a3bfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = Path.home()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd6ab49c-b413-40b3-a4c7-e6f8aca9bc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to the synthetic datasets\n",
    "synthetic_root = HOME / \"work/Datasets/Synthetic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffc9c427-f854-4f19-89ea-9c3f4da06f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_root = Path(\"../logs/taxonomy_classification\")\n",
    "output_root.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4addb47c-2047-4f37-b6bf-bb2e2a8eef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The synthetic datasets to use\n",
    "datasets = [\"Nachusa\", \"Hopland\", \"Wetland\", \"SFD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b88fa60d-b638-45fa-a1da-4b8675c20da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_classifiers = [\"Naive\", \"Bertax\", \"Topdown\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3b693a-7047-4d99-97ea-9b59f228effc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b7ce70d-0015-450d-91e1-10362d6d0a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to enable/disable evalutation cells in this notebook.\n",
    "# This is primarily used as a safety precaution to prevent\n",
    "# overwriting data.\n",
    "COMPUTE_PREDICTIONS = True\n",
    "SKIP_EXISTING = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6213527a-8c9b-45ad-a583-3ef93cdb121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_arguments = [\n",
    "    \"--gpu-ids\", 0\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29dbb0d2-5c41-44ea-9665-4abc1dcae10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastas_to_process(input_path, output_path, skip_existing):\n",
    "    \"\"\"\n",
    "    Find FASTA files to process\n",
    "    \"\"\"\n",
    "    existing_tax_files = set()\n",
    "    if skip_existing:\n",
    "        existing_tax_files.update([f.name for f in output_path.iterdir()])\n",
    "    for f in input_path.iterdir():\n",
    "        if f.suffix != \".fasta\":\n",
    "            continue\n",
    "        if skip_existing and f.with_suffix(\".tax.tsv\").name in existing_tax_files:\n",
    "            continue\n",
    "        yield f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b715c4da-bf70-433e-8b60-25721264858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(name, script, datasets, synthetic_classifiers, python_path=\"python3\", args=None):\n",
    "    assert COMPUTE_PREDICTIONS, \"Evaluation disabled.\"\n",
    "    assert output_root.is_dir(), \"Output directory does not exist.\"\n",
    "    args = args or []\n",
    "    for dataset in datasets:\n",
    "        for synthetic_type in synthetic_classifiers:\n",
    "            path = synthetic_root / dataset / synthetic_type / \"test\"\n",
    "            output_path = output_root / name / dataset / synthetic_type\n",
    "            output_path.mkdir(exist_ok=True, parents=True)\n",
    "            fastas = list(fastas_to_process(path, output_path, SKIP_EXISTING))\n",
    "            subprocess.run(\n",
    "                map(str, [python_path, script, output_path, *args]),\n",
    "                universal_newlines=True,\n",
    "                input='\\n'.join(map(str, fastas))\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7fb702-dd97-4492-a09a-cfd2b4c42663",
   "metadata": {},
   "source": [
    "### Qiime2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ffef7b9c-91f3-4bda-a5a1-48f759acc58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_classifier_path = HOME / \"work/qiime-classifier/classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e343e94c-e8e4-4080-812a-dec146e34f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_workers = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c4a284ac-4071-4c4e-b537-8feef300f5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to: ../logs/qiime_tax_labels/Nachusa/Naive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluate(\n",
    "    \"q2_naive_bayes\",\n",
    "    \"../scripts/taxonomy_eval_qiime.py\",\n",
    "    datasets,\n",
    "    synthetic_classifiers,\n",
    "    python_path=\"/opt/conda/envs/qiime2-2022.8/bin/python3\",\n",
    "    args=[\n",
    "        \"--qiime-classifier-path\", q2_classifier_path,\n",
    "        \"--workers\", max_workers\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40230e9-8475-4995-acb7-eea5d6a4b1ca",
   "metadata": {},
   "source": [
    "### DNABERT (Naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79041b04-ee5b-48d5-8aa1-44ab28bc61b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact = \"sirdavidludwig/dnabert-taxonomy-naive/dnabert-taxonomy-naive-64d-150l:v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73e1372c-3598-44d2-855c-683d63744011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb:   4 of 4 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2100 [00:02<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluate(\n",
    "    \"dnabert_naive\",\n",
    "    \"../scripts/taxonomy_eval_dnabert.py\",\n",
    "    datasets,\n",
    "    synthetic_classifiers,\n",
    "    args=[\n",
    "        \"--model-artifact\", model_artifact,\n",
    "    ] + tf_arguments\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eebb2f-838b-4cce-bea5-33633c68b080",
   "metadata": {},
   "source": [
    "### DNABERT (BERTax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25a45f46-bb96-4c65-92c2-2b22a6071bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact = \"sirdavidludwig/dnabert-taxonomy/dnabert-taxonomy-bertax-64d-150l:v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fb4c44f-c8c8-4aaa-b7e3-0d2161762b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Downloading large artifact dnabert-taxonomy-bertax-64d-150l:v0, 1232.67MB. 4 files... \n",
      "wandb:   4 of 4 files downloaded.  \n",
      "Done. 0:0:1.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:02, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluate(\n",
    "    \"dnabert_bertax\",\n",
    "    \"../scripts/taxonomy_eval_dnabert.py\",\n",
    "    datasets,\n",
    "    synthetic_classifiers,\n",
    "    args=[\n",
    "        \"--model-artifact\", model_artifact,\n",
    "    ] + tf_arguments\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cd835d-91be-46aa-a365-295647124d43",
   "metadata": {},
   "source": [
    "### DNABERT (Top-down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "599ef737-49a3-4cc3-9e3a-436128838dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact = \"sirdavidludwig/dnabert-taxonomy/dnabert-taxonomy-topdown-64d-150l:v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e31abaf0-bbc8-424e-8301-9d9fd3c452c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb:   4 of 4 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:01, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluate(\n",
    "    \"dnabert_topdown\",\n",
    "    \"../scripts/taxonomy_eval_dnabert.py\",\n",
    "    datasets,\n",
    "    synthetic_classifiers,\n",
    "    args=[\n",
    "        \"--model-artifact\", model_artifact,\n",
    "    ] + tf_arguments\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cd5c37-44b5-4b65-a49a-110fa153ee6a",
   "metadata": {},
   "source": [
    "### DNABERT (Deep Top-down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d695a8eb-343c-4d1f-8127-e1ba4f68d0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact = \"sirdavidludwig/dnabert-taxonomy/dnabert-taxonomy-topdown-deep-64d-150l:v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7853acf-44d4-446f-82c0-9e002c2a080c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Downloading large artifact dnabert-taxonomy-topdown-deep-64d-150l:v0, 56.39MB. 4 files... \n",
      "wandb:   4 of 4 files downloaded.  \n",
      "Done. 0:0:0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2100 [00:03<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluate(\n",
    "    \"dnabert_topdown_deep\",\n",
    "    \"../scripts/taxonomy_eval_dnabert.py\",\n",
    "    datasets,\n",
    "    synthetic_classifiers,\n",
    "    args=[\n",
    "        \"--model-artifact\", model_artifact,\n",
    "    ] + tf_arguments\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c935089-e362-4f83-9492-1b2371ff81fa",
   "metadata": {},
   "source": [
    "### SetBERT Top-down (Single-sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7e29ea1-7cd2-4e68-bd73-9fa31f1e3248",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact = \"sirdavidludwig/setbert-taxonomy/setbert-taxonomy-topdown-all-64d-150l:v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f492385-22c9-465f-b4be-2edd0bd3db76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Downloading large artifact setbert-taxonomy-topdown-all-64d-150l:v0, 90.01MB. 4 files... \n",
      "wandb:   4 of 4 files downloaded.  \n",
      "Done. 0:0:0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 24/2049 [00:20<25:36,  1.32it/s] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/subprocess.py:1207\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1209\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/subprocess.py:1941\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1940\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1941\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1942\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1943\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1944\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/subprocess.py:1899\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1898\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1899\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1900\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1901\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1902\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1903\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msetbert_topdown_uniform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../scripts/taxonomy_eval_setbert.py\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynthetic_classifiers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--model-artifact\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_artifact\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--single-sequence\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtf_arguments\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [10], line 11\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(name, script, datasets, synthetic_classifiers, python_path, args)\u001b[0m\n\u001b[1;32m      9\u001b[0m     output_path\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m     fastas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(fastas_to_process(path, output_path, SKIP_EXISTING))\n\u001b[0;32m---> 11\u001b[0m     \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mpython_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscript\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43muniversal_newlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfastas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/subprocess.py:503\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 503\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    505\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/subprocess.py:1144\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1143\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1144\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/subprocess.py:1220\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sigint_wait_secs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# nothing else should wait.\u001b[39;00m\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1220\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msigint_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired:\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/subprocess.py:1935\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1933\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m TimeoutExpired(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, timeout)\n\u001b[1;32m   1934\u001b[0m         delay \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(delay \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, remaining, \u001b[38;5;241m.05\u001b[39m)\n\u001b[0;32m-> 1935\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1936\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1937\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluate(\n",
    "    \"setbert_topdown_uniform\",\n",
    "    \"../scripts/taxonomy_eval_setbert.py\",\n",
    "    datasets,\n",
    "    synthetic_classifiers,\n",
    "    args=[\n",
    "        \"--model-artifact\", model_artifact,\n",
    "        \"--single-sequence\"\n",
    "    ] + tf_arguments\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dd3910-ccd2-47c6-a85f-ce9e8273d7eb",
   "metadata": {},
   "source": [
    "### SetBERT (Naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc0d44a-8bd8-4883-a052-4aa6c2f19f38",
   "metadata": {},
   "source": [
    "### SetBERT (BERTax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2987c7e4-a8dc-4990-bacc-056d0fb84676",
   "metadata": {},
   "source": [
    "N/A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad2d2b1-0c4d-4be5-99fb-8e65905d609d",
   "metadata": {},
   "source": [
    "### SetBERT (Top-down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5728a18e-4c71-417c-9329-99ec7a9825a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fine-tuned SetBERT top-down taxonomy model\n",
    "model_artifact = \"sirdavidludwig/setbert-taxonomy/setbert-taxonomy-topdown-all-64d-150l:v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bdb3a56-d840-4d6e-8037-b75286f45c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Downloading large artifact setbert-taxonomy-topdown-all-64d-150l:v0, 90.01MB. 4 files... \n",
      "wandb:   4 of 4 files downloaded.  \n",
      "Done. 0:0:0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:02, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluate(\n",
    "    \"setbert_topdown\",\n",
    "    \"../scripts/taxonomy_eval_setbert.py\",\n",
    "    datasets,\n",
    "    synthetic_classifiers,\n",
    "    args=[\n",
    "        \"--model-artifact\", model_artifact,\n",
    "    ] + tf_arguments\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
